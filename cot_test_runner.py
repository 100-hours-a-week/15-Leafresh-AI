"""
CoT(Chain of Thought) í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""
import asyncio
import json
import time
from typing import Dict, Any, List
import httpx
from langfuse_config import langfuse_config, cot_evaluator
from cot_test_data import get_all_test_cases, format_cot_prompt

class CoTTestRunner:
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.client = httpx.AsyncClient(timeout=30.0)
    
    async def run_base_info_test(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ë³¸ ì •ë³´ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        trace_id = langfuse_config.create_trace(
            name=f"CoT_BaseInfo_Test_{test_case['id']}",
            metadata={
                "test_id": test_case["id"],
                "category": test_case["category"],
                "input": test_case["input"]
            }
        )
        
        try:
            # API í˜¸ì¶œ
            response = await self.client.post(
                f"{self.base_url}/ai/chatbot/recommendation/base-info",
                json=test_case["input"]
            )
            
            if response.status_code == 200:
                result = response.json()
                recommendation = result.get("data", {}).get("recommend", "")
                
                # CoT í‰ê°€ ì‹¤í–‰
                scores = await self.evaluate_cot_response(
                    trace_id, recommendation, test_case["expected_keywords"]
                )
                
                return {
                    "test_id": test_case["id"],
                    "status": "success",
                    "trace_id": trace_id,
                    "response": recommendation,
                    "scores": scores,
                    "api_response": result
                }
            else:
                return {
                    "test_id": test_case["id"],
                    "status": "error",
                    "trace_id": trace_id,
                    "error": f"API Error: {response.status_code}",
                    "response_text": response.text
                }
                
        except Exception as e:
            return {
                "test_id": test_case["id"],
                "status": "error",
                "trace_id": trace_id,
                "error": str(e)
            }
    
    async def run_free_text_test(self, test_case: Dict[str, Any]) -> Dict[str, Any]:
        """ììœ  í…ìŠ¤íŠ¸ ê¸°ë°˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        trace_id = langfuse_config.create_trace(
            name=f"CoT_FreeText_Test_{test_case['id']}",
            metadata={
                "test_id": test_case["id"],
                "category": test_case["category"],
                "input": test_case["input"]
            }
        )
        
        try:
            # API í˜¸ì¶œ
            response = await self.client.post(
                f"{self.base_url}/ai/chatbot/recommendation/free-text",
                json=test_case["input"]
            )
            
            if response.status_code == 200:
                result = response.json()
                recommendation = result.get("data", {}).get("recommend", "")
                
                # CoT í‰ê°€ ì‹¤í–‰
                scores = await self.evaluate_cot_response(
                    trace_id, recommendation, test_case["expected_keywords"]
                )
                
                return {
                    "test_id": test_case["id"],
                    "status": "success",
                    "trace_id": trace_id,
                    "response": recommendation,
                    "scores": scores,
                    "api_response": result
                }
            else:
                return {
                    "test_id": test_case["id"],
                    "status": "error",
                    "trace_id": trace_id,
                    "error": f"API Error: {response.status_code}",
                    "response_text": response.text
                }
                
        except Exception as e:
            return {
                "test_id": test_case["id"],
                "status": "error",
                "trace_id": trace_id,
                "error": str(e)
            }
    
    async def evaluate_cot_response(self, trace_id: str, response: str, expected_keywords: List[str]) -> Dict[str, float]:
        """CoT ì‘ë‹µ í‰ê°€"""
        scores = {}
        
        # ì‚¬ê³  ê³¼ì • í‰ê°€
        scores["thought_process"] = cot_evaluator.evaluate_thought_process(
            trace_id, response, expected_keywords
        )
        
        # ì¶”ë¡  ë‹¨ê³„ í‰ê°€
        scores["reasoning_steps"] = cot_evaluator.evaluate_reasoning_steps(
            trace_id, response
        )
        
        # ë…¼ë¦¬ì  íë¦„ í‰ê°€
        scores["logical_flow"] = cot_evaluator.evaluate_logical_flow(
            trace_id, response
        )
        
        # ì™„ì„±ë„ í‰ê°€
        scores["completeness"] = cot_evaluator.evaluate_completeness(
            trace_id, response
        )
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        weights = {
            "thought_process": 0.4,
            "reasoning_steps": 0.3,
            "logical_flow": 0.2,
            "completeness": 0.1
        }
        
        total_score = sum(scores[key] * weights[key] for key in scores)
        scores["total"] = total_score
        
        # ì¢…í•© ì ìˆ˜ ë¡œê¹…
        langfuse_config.log_score(
            trace_id=trace_id,
            name="cot_total_score",
            value=total_score,
            comment=f"Total CoT Score: {total_score:.3f}",
            metadata={
                "individual_scores": scores,
                "weights": weights
            }
        )
        
        return scores
    
    async def run_all_tests(self) -> List[Dict[str, Any]]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        test_cases = get_all_test_cases()
        results = []
        
        print(f"ğŸš€ CoT í…ŒìŠ¤íŠ¸ ì‹œì‘: {len(test_cases)}ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤")
        print("=" * 50)
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"ğŸ“ í…ŒìŠ¤íŠ¸ {i}/{len(test_cases)}: {test_case['id']}")
            
            if test_case["category"] == "base_info":
                result = await self.run_base_info_test(test_case)
            else:
                result = await self.run_free_text_test(test_case)
            
            results.append(result)
            
            # ê²°ê³¼ ì¶œë ¥
            if result["status"] == "success":
                scores = result["scores"]
                print(f"âœ… ì„±ê³µ - ì´ì : {scores['total']:.3f}")
                print(f"   ì‚¬ê³ ê³¼ì •: {scores['thought_process']:.3f}")
                print(f"   ì¶”ë¡ ë‹¨ê³„: {scores['reasoning_steps']:.3f}")
                print(f"   ë…¼ë¦¬íë¦„: {scores['logical_flow']:.3f}")
                print(f"   ì™„ì„±ë„: {scores['completeness']:.3f}")
            else:
                print(f"âŒ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            
            print(f"   Trace ID: {result['trace_id']}")
            print("-" * 30)
            
            # í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²©
            await asyncio.sleep(1)
        
        await self.client.aclose()
        return results
    
    def generate_report(self, results: List[Dict[str, Any]]) -> str:
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        successful_tests = [r for r in results if r["status"] == "success"]
        failed_tests = [r for r in results if r["status"] == "error"]
        
        report = f"""
# CoT í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¦¬í¬íŠ¸

## ğŸ“Š ì „ì²´ í†µê³„
- ì´ í…ŒìŠ¤íŠ¸: {len(results)}ê°œ
- ì„±ê³µ: {len(successful_tests)}ê°œ
- ì‹¤íŒ¨: {len(failed_tests)}ê°œ
- ì„±ê³µë¥ : {len(successful_tests)/len(results)*100:.1f}%

## ğŸ¯ ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ ìƒì„¸ ê²°ê³¼
"""
        
        if successful_tests:
            total_scores = [r["scores"]["total"] for r in successful_tests]
            avg_score = sum(total_scores) / len(total_scores)
            
            report += f"""
### í‰ê·  ì ìˆ˜: {avg_score:.3f}

| í…ŒìŠ¤íŠ¸ ID | ì´ì  | ì‚¬ê³ ê³¼ì • | ì¶”ë¡ ë‹¨ê³„ | ë…¼ë¦¬íë¦„ | ì™„ì„±ë„ | Trace ID |
|-----------|------|----------|----------|----------|--------|----------|
"""
            
            for result in successful_tests:
                scores = result["scores"]
                report += f"| {result['test_id']} | {scores['total']:.3f} | {scores['thought_process']:.3f} | {scores['reasoning_steps']:.3f} | {scores['logical_flow']:.3f} | {scores['completeness']:.3f} | {result['trace_id']} |\n"
        
        if failed_tests:
            report += f"""
## âŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸
"""
            for result in failed_tests:
                report += f"- {result['test_id']}: {result.get('error', 'Unknown error')}\n"
        
        report += f"""
## ğŸ”— Langfuse ëŒ€ì‹œë³´ë“œ
í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ìì„¸íˆ ë³´ë ¤ë©´ Langfuse ëŒ€ì‹œë³´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.
ê° í…ŒìŠ¤íŠ¸ì˜ Trace IDë¥¼ ì‚¬ìš©í•˜ì—¬ ê°œë³„ ê²°ê³¼ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
        
        return report

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    runner = CoTTestRunner()
    
    try:
        results = await runner.run_all_tests()
        report = runner.generate_report(results)
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        with open("cot_test_report.md", "w", encoding="utf-8") as f:
            f.write(report)
        
        print("\n" + "=" * 50)
        print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼ê°€ cot_test_report.mdì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("=" * 50)
        print(report)
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    asyncio.run(main()) 