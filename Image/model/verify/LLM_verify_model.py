from vertexai import init
from vertexai.preview.generative_models import GenerativeModel
from dotenv import load_dotenv
import os
import requests

# ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• 
from PIL import Image as PILImage
from vertexai.preview.generative_models import Image as VertexImage   # vertexAIì—ì„œë§Œ ì‚¬ìš© 

# GCP Cloud Storage ì—°ê²°
from google.cloud import storage  
import tempfile                     # ì„ì‹œ íŒŒì¼ ì €ì¥ìš©

# LangChain PromptTemplate ì ìš©
from model.verify.event_challenge_prompt import event_challenge_prompts
from model.verify.group_prompt_generator import get_or_create_group_prompt
from model.verify.personal_challenge_prompt import personal_challenge_prompts

# LLaVA ëª¨ë¸ ë¡œë“œ
from transformers import AutoProcessor, AutoModelForVision2Seq
import torch

class ImageVerifyModel :
    '''
    def __init__(self, credential_env="GOOGLE_APPLICATION_CREDENTIALS", project_id="leafresh", region="us-central1"): 
        # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ë° ì¸ì¦ ì´ˆê¸°í™”
        load_dotenv()
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.getenv(credential_env)
        init(project=project_id, location=region)                                       # Vertex AI í”„ë¡œì íŠ¸/ë¦¬ì „ ì´ˆê¸°í™”
        self.model = GenerativeModel("gemini-2.0-flash")                                # ëª¨ë¸ ì •ì˜
        self.storage_client = storage.Client()                                          # GCS í´ë¼ì´ì–¸íŠ¸ 
    '''

    def __init__(self, model_dir="/home/ubuntu/llava_model/models--llava-hf--llava-1.5-13b-hf/snapshots/5dda2880bda009266dda7c4baff660b95ca64540", device="cuda"):
        self.device = device
        self.processor = AutoProcessor.from_pretrained(model_dir)
        self.model = AutoModelForVision2Seq.from_pretrained(model_dir, torch_dtype=torch.float16, device_map="auto", local_files_only=True)
        self.storage_client = storage.Client()                                          


    def image_verify(self, bucket_name: str, blob_name: str, challenge_type: str, challenge_id: int, challenge_name: str, challenge_info: str) -> str :
        try:
            print("[DEBUG] image_verify ì§„ì…")
            bucket = self.storage_client.bucket(bucket_name)                            # ì´ë¯¸ì§€ ì—…ë¡œë“œ 
            blob = bucket.blob(blob_name)  
            print("[DEBUG] GCS bucket, blob ê°€ì ¸ì˜´")                               
       
            with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as temp_file:
                blob.download_to_filename(temp_file.name) 
                print("[DEBUG] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")

                # ì´ë¯¸ì§€ ì—´ê¸°
                pillow_image = PILImage.open(temp_file.name).convert("RGB")
                print("[DEBUG] ì´ë¯¸ì§€ ì—´ê¸° ì™„ë£Œ")

                # ì´ë²¤íŠ¸ ì±Œë¦°ì§€ì¸ ê²½ìš°ì—ë§Œ ë¦¬ì‚¬ì´ì§• ìˆ˜í–‰
                if challenge_type.upper() == "GROUP" and 1 <= challenge_id <= 17:
                    if max(pillow_image.size) > 1024:
                        print("[DEBUG] ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• ì‹œì‘")
                        new_width = 1024
                        new_height = int(pillow_image.height * 1024 / pillow_image.width)
                        pillow_image = pillow_image.resize((new_width, new_height))
                    pillow_image.save(temp_file.name, format="PNG")

                # VertexAIìš© ì´ë¯¸ì§€ ê°ì²´ ë¡œë“œ 
                # image = VertexImage.load_from_file(temp_file.name)

            print("[DEBUG] response í˜¸ì¶œ ì „")
            return self.response(pillow_image, challenge_type, challenge_id, challenge_name, challenge_info)

        except Exception as e:
            return f"[ì—ëŸ¬] GCS ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}" 


    def select_prompt(self, challenge_type: str, challenge_id: int, challenge_name: str, challenge_info: str):
        if challenge_type.upper() == "GROUP" :
            if 1 <= challenge_id <= 17:
                return event_challenge_prompts.get(challenge_id)
            else: 
                return get_or_create_group_prompt(challenge_id, challenge_name, challenge_info)
        elif challenge_type.upper() == "PERSONAL" :
            return personal_challenge_prompts.get(challenge_id)
            
        return None

    def response(self, image, challenge_type, challenge_id, challenge_name, challenge_info):
        prompt_template = self.select_prompt(challenge_type, challenge_id, challenge_name, challenge_info)
        print("[DEBUG] PromptTemplate:", prompt_template)

        # LangChain PromptTemplate ê°ì²´ì¸ ê²½ìš° 
        if hasattr(prompt_template, "format_prompt"):
            prompt = prompt_template.format_prompt().to_string()
        # ë‹¨ì²´ ì±Œë¦°ì§€ì—ì„œ ì§ì ‘ ìƒì„±í•œ stringì˜ ê²½ìš° 
        elif isinstance(prompt_template, str):
            prompt = prompt_template
        # ê¸°ë³¸ ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ 
        else:
            prompt = (
                f"ì´ ì´ë¯¸ì§€ëŠ” '{challenge_name}'ì— ì í•©í•œ ì´ë¯¸ì§€ ì¸ê°€ìš”? \n"
                "ë¶„ìœ„ê¸°ê°€ ì•„ë‹ˆë¼ ë¬¼ì²´ê°€ ì¡´ì¬í•´ì•¼í•©ë‹ˆë‹¤. í…€ë¸”ëŸ¬ë¥¼ ì‚¬ìš©í•œ ê²ƒì´ ë§ìœ¼ë©´ ëª¨ë‘ 'ì˜ˆ'ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”. \n"
                "ê³ ê¸°ë¥¼ ì œì™¸í•˜ê³  ìƒì„ ì€ ìƒëŸ¬ë“œ/ì±„ì‹ ì‹ë‹¨ìœ¼ë¡œ ëª¨ë‘ 'ì˜ˆ'ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”. \n"
                "ì¥ë°”êµ¬ë‹ˆ/ì—ì½”ë°± ì±Œë¦°ì§€ì˜ ê²½ìš° ê°€ë°©ì´ ì˜ ë‚˜ì™€ìˆë‹¤ë©´ ëª¨ë‘ 'ì˜ˆ'ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”. \n"
                "ë§Œë³´ ê±·ê¸° ì±Œë¦°ì§€ ê°™ì€ ê²½ìš° 10000ì´ìƒì¸ ìˆ«ìê°€ ìˆìœ¼ë©´ 'ì˜ˆ'ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”. \n"
                "ì‘ì€ í…ƒë°­ ê°€ê¾¸ê¸°ëŠ” ì‘ì€ í™”ë‹¨ì˜ ëª¨ìŠµì´ ë‚˜ì™”ì„ ê²½ìš° 'ì˜ˆ'ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”. \n"
                "ë„ˆë¬´ ì´ë¯¸ì§€ê°€ íë¦¬ê±°ë‚˜ ë¸”ëŸ¬ ì²˜ë¦¬ ë˜ì–´ìˆëŠ” ê²½ìš° ë¬´ì¡°ê±´ 'ì•„ë‹ˆì˜¤'ë¥¼ ì¶œë ¥í•´ì£¼ì„¸ìš”. \n"
                "ì í•©í•œ ì´ë¯¸ì§€ì¸ì§€ ì˜ˆ/ì•„ë‹ˆì˜¤ë¡œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”. ê²°ê³¼ëŠ” ë¬´ì¡°ê±´ ì˜ˆ/ì•„ë‹ˆì˜¤ ë¡œë§Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”. \n"
            )

        
        # vertex AI API ì‚¬ìš©   
        # result = self.model.generate_content(
        #     [prompt, image],
        #     generation_config={
        #         "temperature": 0.4,
        #         "top_p": 1,
        #         "top_k": 32,
        #         "max_output_tokens": 512
        #     }
        # )

        # return result.text
        

        # ì´ë¯¸ì§€ ì—´ê¸°
        image_tensor = self.processor(images=image, return_tensors="pt").pixel_values
        inputs = self.processor(prompt, return_tensors="pt")

        # ëª¨ë¸ ì¸í¼ëŸ°ìŠ¤
        outputs = self.model.generate(
            input_ids=inputs["input_ids"],
            pixel_values=image_tensor,
            max_new_tokens=50
        )

        assistant = self.processor.decode(outputs[0], skip_special_tokens=True)

        print("\n[ğŸ“¢ LLaVA ì‘ë‹µ í™•ì¸]")
        print(assistant)
 
        if "ASSISTANT:" in assistant:
            result = assistant.split("ASSISTANT:")[-1].strip()
        else:
            result = assistant.strip()

        return result
        
        

