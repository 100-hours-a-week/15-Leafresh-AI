from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_qdrant import Qdrant
from langchain_community.embeddings import SentenceTransformerEmbeddings
from qdrant_client import QdrantClient
from dotenv import load_dotenv
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.memory import ConversationBufferMemory
from typing import Dict, Generator, Any, List, Optional, TypedDict, Annotated, Sequence
from Text.LLM.model.chatbot.chatbot_constants import label_mapping, category_keywords
import os
import json
import re
import logging
import httpx
import unicodedata
import random

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Qdrant Cloud URLì„ ì‚¬ìš©í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ë„ë¡ ìˆ˜ì •
qdrant_client = QdrantClient(
    url=os.getenv("QDRANT_URL"),
    api_key=os.getenv("QDRANT_API_KEY")
)

embeddings = SentenceTransformerEmbeddings(
    model_name="BAAI/bge-small-en-v1.5",
    model_kwargs={'device': 'cpu'}
)

# Qdrant DB ì—°ê²°
qdrant = Qdrant(
    client=qdrant_client,
    collection_name=os.getenv("QDRANT_COLLECTION_NAME"),
    embeddings=embeddings,
)
retriever = qdrant.as_retriever(search_kwargs={"k": 3})

logger.info("Qdrant DB for free-text chatbot connected successfully.")

class ChatState(TypedDict):
    messages: Annotated[Sequence[Dict[str, str]], "ëŒ€í™” ê¸°ë¡"]
    current_query: str
    context: str
    response: str
    should_continue: bool
    error: Optional[str]
    docs: Optional[list]
    sessionId: str
    category: Optional[str]
    base_category: Optional[str]

conversation_states: Dict[str, ChatState] = {}

free_text_response_schemas = [
    ResponseSchema(name="recommend", description="ì¶”ì²œ í…ìŠ¤íŠ¸ë¥¼ í•œê¸€ë¡œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶œë ¥í•´ ì£¼ì„¸ìš”. (ì˜ˆ: 'ì´ëŸ° ì±Œë¦°ì§€ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.')"),
    ResponseSchema(name="challenges", description="ì¶”ì²œ ì±Œë¦°ì§€ ë¦¬ìŠ¤íŠ¸, ê° í•­ëª©ì€ title, description í¬í•¨, descriptionì€ í•œê¸€ë¡œ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.")
]

free_text_parser = StructuredOutputParser.from_response_schemas(free_text_response_schemas)

# [ë³€ê²½ì‚¬í•­ ì£¼ì„] 2024-07-31
# í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ëª…ì„ custom_promptë¡œ ì§€ì •
custom_prompt = PromptTemplate(
    input_variables=["context", "query", "messages", "category"],
    template="""ë„ˆëŠ” ì‚¬ìš©ìì˜ ì¼ìƒ ëŒ€í™”ë¥¼ ì´í•´í•˜ê³ , ëŒ€í™”ì˜ ë§¥ë½ì— ë§ì¶° ì¹œí™˜ê²½ ì±Œë¦°ì§€ë¥¼ ì¶”ì²œí•˜ëŠ” ì±—ë´‡ì´ì•¼.

[ëŒ€í™” ê¸°ë¡]
{messages}

[ê´€ë ¨ ì •ë³´]
{context}

[ì‚¬ìš©ì í˜„ì¬ ì…ë ¥]
{query}

[ê´€ì‹¬ ì¹´í…Œê³ ë¦¬]
{category}

[ì¤‘ìš” ìš”êµ¬ì‚¬í•­]
- ëŒ€í™”ì˜ íë¦„ê³¼ ê´€ë ¨ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬, ì‚¬ìš©ìê°€ í¥ë¯¸ë¥¼ ëŠë‚„ ë§Œí•œ ì¹œí™˜ê²½ ì±Œë¦°ì§€ 3ê°€ì§€ë¥¼ ì¶”ì²œí•´ì¤˜.
- ë°˜ë“œì‹œ ì•„ë˜ ì˜ˆì‹œì™€ ê°™ì€ ë§ˆí¬ë‹¤ìš´ê³¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•´. ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆ.
- ëª¨ë“  ë‚´ìš©ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ê³ , ë¬¸ì¥ ëì€ "ë‹ˆë‹¤." ë˜ëŠ” "ìš”."ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëë‚´ì¤˜.
- ê° ì±Œë¦°ì§€ëŠ” "title"ê³¼ "description" í•„ë“œë§Œ í¬í•¨í•´ì•¼ í•´.
- "title"ì€ "1. ", "2. ", "3. " í˜•ì‹ìœ¼ë¡œ ë²ˆí˜¸ë¥¼ ë¶™ì—¬ì„œ ì‹œì‘í•´.
- "description"ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì¤˜.
- ì˜ì–´, ì´ëª¨í‹°ì½˜, ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ìëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆ.

[ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
```json
{{
    "recommend": "ëŒ€í™”ì˜ ë§¥ë½ì— ë”°ë¼ ì´ëŸ° ì±Œë¦°ì§€ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.",
    "challenges": [
        {{"title": "ì²«ë²ˆì§¸ ì±Œë¦°ì§€:", "description": "ê°„ë‹¨í•œ ì„¤ëª…"}},
        {{"title": "ë‘ë²ˆì§¸ ì±Œë¦°ì§€:", "description": "ê°„ë‹¨í•œ ì„¤ëª…"}},
        {{"title": "ì„¸ë²ˆì§¸ ì±Œë¦°ì§€:", "description": "ê°„ë‹¨í•œ ì„¤ëª…"}}
    ]
}}
```
"""
)

def get_llm_response(query: str, chat_history: List[Dict[str, str]], context: str, category: str) -> Generator[Dict[str, Any], None, None]:
    """
    ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ì™€ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ vLLMì— ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ì„ ë³´ë‚´ê³ ,
    ëª¨ë¸ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë„ì–´ì“°ê¸°ê°€ í¬í•¨ëœ ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    memory = ConversationBufferMemory(return_messages=True)
    for msg in chat_history:
        if msg['role'] == 'user':
            memory.chat_memory.add_user_message(msg['content'])
        else:
            memory.chat_memory.add_ai_message(msg['content'])
    messages = memory.chat_memory.messages

    # custom_prompt ë³€ìˆ˜ëª…ì„ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
    final_prompt = custom_prompt.format(
        query=query,
        messages=messages,
        context=context,
        category=category
    )

    logger.info(f"[vLLM í˜¸ì¶œ] í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(final_prompt)}")
    url = "http://localhost:8800/v1/chat/completions"
    payload = {
        "model": "/home/ubuntu/mistral_finetuned_v5/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/0d4b76e1efeb5eb6f6b5e757c79870472e04bd3a",
        "messages": [{"role": "user", "content": final_prompt}],
        "stream": True, "max_tokens": 1024, "temperature": 0.7, "do_sample": True
    }

    response_completed = False
    full_response = ""
    streaming_buffer = ""
    recommend_sentence_finished = False
    full_cleaned_text_stream = ""
    
    try:
        with httpx.stream("POST", url, json=payload, timeout=60.0) as response:
            response.raise_for_status()
            for line in response.iter_lines():
                if line.startswith("data: "):
                    json_str = line[len("data: "):]
                    if json_str.strip() == "[DONE]": break
                    
                    try:
                        json_data = json.loads(json_str)
                        token = json_data["choices"][0]["delta"].get("content", "")
                        if not token: continue
                        
                        logger.info(f"í† í° ìˆ˜ì‹ : {token[:20]}...")
                        full_response += token
                        streaming_buffer += token
                        
                        if ' ' in streaming_buffer:
                            parts = streaming_buffer.rsplit(' ', 1)
                            to_flush = parts[0] + ' '
                            streaming_buffer = parts[1]

                            if to_flush:
                                cleaned_text = re.sub(r'"(recommend|challenges|title|description)":\s*("|\')?', '', to_flush)
                                cleaned_text = cleaned_text.replace("```json", "").replace("```", "")
                                cleaned_text = re.sub(r'["\']', '', cleaned_text)
                                cleaned_text = re.sub(r'[\[\]{}$]', '', cleaned_text)
                                cleaned_text = re.sub(r',\s*$', '', cleaned_text)
                                
                                if cleaned_text.strip() and not response_completed:
                                    challenge_start_match = re.search(r'(2\.|3\.)', cleaned_text)
                                    if challenge_start_match:
                                        start_index = challenge_start_match.start()
                                        part_before_challenge = cleaned_text[:start_index]
                                        part_after_challenge = cleaned_text[start_index:]

                                        if part_before_challenge.strip():
                                            yield {"event": "challenge", "data": json.dumps({"status": 200, "message": "í† í° ìƒì„±", "data": part_before_challenge}, ensure_ascii=False)}
                                        yield {"event": "challenge", "data": json.dumps({"status": 200, "message": "í† í° ìƒì„±", "data": "\n\n"}, ensure_ascii=False)}
                                        yield {"event": "challenge", "data": json.dumps({"status": 200, "message": "í† í° ìƒì„±", "data": part_after_challenge}, ensure_ascii=False)}
                                        full_cleaned_text_stream += cleaned_text
                                    else:
                                        yield {"event": "challenge", "data": json.dumps({"status": 200, "message": "í† í° ìƒì„±", "data": cleaned_text}, ensure_ascii=False)}
                                        full_cleaned_text_stream += cleaned_text
                                    
                                    recommend_endings = ["ì¶”ì²œí•©ë‹ˆë‹¤.", "ì¶”ì²œë“œë ¤ìš”.", "ì¶”ì²œí•´ìš”.", "ê¶Œì¥í•©ë‹ˆë‹¤."]
                                    if not recommend_sentence_finished and any(full_cleaned_text_stream.strip().endswith(ending) for ending in recommend_endings):
                                        yield {"event": "challenge", "data": json.dumps({"status": 200, "message": "í† í° ìƒì„±", "data": "\n\n"}, ensure_ascii=False)}
                                        recommend_sentence_finished = True
                                
                    except json.JSONDecodeError:
                        logger.warning(f"JSON ë””ì½”ë”© ì‹¤íŒ¨: {json_str}")
                        continue

            if streaming_buffer:
                cleaned_text = re.sub(r'"(recommend|challenges|title|description)":\s*("|\')?', '', streaming_buffer)
                cleaned_text = cleaned_text.replace("```json", "").replace("```", "")
                cleaned_text = re.sub(r'["\']', '', cleaned_text)
                cleaned_text = re.sub(r'[\[\]{}$]', '', cleaned_text)
                cleaned_text = re.sub(r',\s*$', '', cleaned_text)
                
                if cleaned_text.strip() and not response_completed:
                    yield {"event": "challenge", "data": json.dumps({"status": 200, "message": "í† í° ìƒì„±", "data": cleaned_text.strip()}, ensure_ascii=False)}
                    full_cleaned_text_stream += cleaned_text.strip()
                    recommend_endings = ["ì¶”ì²œí•©ë‹ˆë‹¤.", "ì¶”ì²œë“œë ¤ìš”.", "ì¶”ì²œí•´ìš”.", "ê¶Œì¥í•©ë‹ˆë‹¤."]
                    if not recommend_sentence_finished and any(full_cleaned_text_stream.strip().endswith(ending) for ending in recommend_endings):
                        yield {"event": "challenge", "data": json.dumps({"status": 200, "message": "í† í° ìƒì„±", "data": "\n\n"}, ensure_ascii=False)}
                        recommend_sentence_finished = True

        logger.info("ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ. ì „ì²´ ì‘ë‹µ íŒŒì‹± ì‹œì‘.")
        
        match = re.search(r'```json\s*([\s\S]*?)\s*```', full_response)
        if match:
            json_str = match.group(1)
        else:
            start_idx = full_response.find('{')
            end_idx = full_response.rfind('}') + 1
            if start_idx != -1 and end_idx != 0:
                json_str = full_response[start_idx:end_idx]
            else:
                raise ValueError("ì‘ë‹µì—ì„œ ìœ íš¨í•œ JSON ê°ì²´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        json_str = re.sub(r',\s*([}\]])', r'\1', json_str)

        try:
            parsed_data = json.loads(json_str)
            
            if not response_completed:
                response_completed = True
                yield {
                    "event": "close",
                    "data": json.dumps({
                        "status": 200,
                        "message": "ëª¨ë“  ì±Œë¦°ì§€ ì¶”ì²œ ì™„ë£Œ",
                        "data": parsed_data
                    }, ensure_ascii=False)
                }
        except json.JSONDecodeError as e:
            logger.error(f"ìµœì¢… JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.error(f"íŒŒì‹± ì‹œë„í•œ ë¬¸ìì—´: {json_str}")
            if not response_completed:
                response_completed = True
                yield {"event": "error", "data": json.dumps({"status": 500, "message": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}", "data": full_response}, ensure_ascii=False)}

    except httpx.HTTPStatusError as e:
        logger.error(f"vLLM ì„œë²„ ì˜¤ë¥˜: {e.response.status_code} - {e.response.text}")
        if not response_completed:
            yield {"event": "error", "data": json.dumps({"status": 500, "message": f"vLLM ì„œë²„ ì˜¤ë¥˜: {e.response.text}"})}
    except Exception as e:
        logger.error(f"[vLLM í˜¸ì¶œ ì‹¤íŒ¨] {str(e)}")
        if not response_completed:
            yield {"event": "error", "data": json.dumps({"status": 500, "message": f"vLLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"}, ensure_ascii=False)}

def process_chat(sessionId: str, query: str, base_info_category: Optional[str] = None) -> Generator[Dict[str, Any], None, None]:
    """ëŒ€í™” ìƒíƒœë¥¼ ê´€ë¦¬í•˜ê³  ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    logger.info(f"ğŸš€ğŸš€ğŸš€ ììœ  ëŒ€í™” ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ğŸš€ï¿½ğŸš€")
    logger.info(f"ì„¸ì…˜ ID: {sessionId}, ì‚¬ìš©ì ì§ˆë¬¸: {query}")

    # 1. ì„¸ì…˜ ìƒíƒœ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ì´ˆê¸°í™”
    if sessionId not in conversation_states:
        initial_category = base_info_category or "ì œë¡œì›¨ì´ìŠ¤íŠ¸"
        logger.info(f"ìƒˆë¡œìš´ ì„¸ì…˜ ê°ì§€. ì¹´í…Œê³ ë¦¬ ì´ˆê¸°í™”: {initial_category}")
        conversation_states[sessionId] = {
            "messages": [], "category": initial_category, "base_category": initial_category,
            "current_query": "", "context": "", "response": "", "should_continue": True,
            "error": None, "docs": None, "sessionId": sessionId
        }
    
    state = conversation_states[sessionId]
    state['messages'].append({'role': 'user', 'content': query})
    state['current_query'] = query

    # 2. ì¹´í…Œê³ ë¦¬, ìœ„ì¹˜, ì§ì—… ë³€ê²½ ë¡œì§
    category_changed = False
    query_lower = query.lower()

    # ğŸ” ìœ„ì¹˜(location) ë° ì§ì—…(workType) ìë™ ì¶”ì¶œ ë¡œì§ ì¶”ê°€
    # ìœ„ì¹˜ ê´€ë ¨ í‚¤ì›Œë“œ ë§¤í•‘
    location_keywords = {
        "ë„ì‹œ": ["ë„ì‹œ", "ì‹œë‚´", "ê±´ë¬¼", "ì•„íŒŒíŠ¸"],
        "í•´ì•ˆê°€": ["ë°”ë‹¤", "í•´ë³€", "í•´ì•ˆ", "ì—°ì•ˆ", "í•´ì•ˆê°€"],
        "ì‚°": ["ì‚°", "ì‚°ê°„", "ë“±ì‚°", "ê³ ì§€ëŒ€"],
        "ë†ì´Œ": ["ë†ì´Œ", "ë“¤íŒ", "ë…¼", "ë°­", "ì‹œê³¨"]
    }

    # ì§ì—…(ê·¼ë¬´ í˜•íƒœ) ê´€ë ¨ í‚¤ì›Œë“œ ë§¤í•‘
    work_type_keywords = {
        "ì‚¬ë¬´ì§": ["ì‚¬ë¬´ì‹¤", "ì˜¤í”¼ìŠ¤", "ì»´í“¨í„°", "ì•‰ì•„ì„œ", "íšŒì˜", "ë¬¸ì„œ"],
        "ì˜ì—…ì§": ["ì˜ì—…", "íŒë§¤", "ê³ ê°", "ì™¸ê·¼", "ì¶œì¥", "ìƒë‹´"],
        "í˜„ì¥ì§": ["í˜„ì¥", "ì‘ì—…", "ê±´ì„¤", "ë…¸ë™", "í˜„ì¥ì—ì„œ"],
        "ì¬íƒê·¼ë¬´": ["ì¬íƒ", "ì§‘", "ì›ê²©", "ì¬íƒê·¼ë¬´", "í™ˆì˜¤í”¼ìŠ¤"]
    }

    # ìœ„ì¹˜ ìë™ ë³€ê²½ (ììœ  ì±„íŒ… ë‚´ìš©ì— í¬í•¨ëœ í‚¤ì›Œë“œ ê¸°ë°˜)
    for loc, keywords in location_keywords.items():
        if any(kw in query_lower for kw in keywords):
            state["location"] = loc
            logger.info(f"ğŸ’¡ ìœ„ì¹˜ ë³€ê²½ ê°ì§€: {loc}")
            break

    # ì§ì—… ìë™ ë³€ê²½ (ììœ  ì±„íŒ… ë‚´ìš©ì— í¬í•¨ëœ í‚¤ì›Œë“œ ê¸°ë°˜)
    for work, keywords in work_type_keywords.items():
        if any(kw in query_lower for kw in keywords):
            state["workType"] = work
            logger.info(f"ğŸ’¡ ì§ì—… ë³€ê²½ ê°ì§€: {work}")
            break

    # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ë³€ê²½ ë¡œì§
    if any(keyword in query_lower for keyword in ["ì›ë˜", "ì²˜ìŒ", "ì´ì „", "ì›ë˜ëŒ€ë¡œ", "ê¸°ì¡´"]):
        state["category"] = state["base_category"]
        category_changed = True
        logger.info(f"ì¹´í…Œê³ ë¦¬ ì›ë³µ: {state['category']}")
    elif any(keyword in query_lower for keyword in ["ì•„ë¬´", "ì•„ë¬´ê±°ë‚˜", "ë‹¤ë¥¸ê±°", "ìƒˆë¡œìš´ê±°", "ë”´ê±°", "ë‹¤ë¥¸"]):
        available_categories = [cat for cat in label_mapping.keys() if cat != state["category"]]
        if not available_categories:
            available_categories = list(label_mapping.keys())
        state["category"] = random.choice(available_categories)
        category_changed = True
        logger.info(f"ì¹´í…Œê³ ë¦¬ ëœë¤ ë³€ê²½: {state['category']}")
    else:
        for cat, keywords in category_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                state["category"] = cat
                category_changed = True
                logger.info(f"í‚¤ì›Œë“œ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ë³€ê²½: {state['category']}")
                break

    if not category_changed:
        logger.info(f"ì¹´í…Œê³ ë¦¬ ë³€ê²½ ì—†ìŒ. ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ ìœ ì§€: {state['category']}")

    # 3. RAG ë¬¸ì„œ ê²€ìƒ‰
    try:
        docs = retriever.get_relevant_documents(query)
        state["docs"] = docs
        state["context"] = "\n".join([doc.page_content for doc in docs])
        if not docs:
            logger.warning("ê´€ë ¨ëœ ì±Œë¦°ì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        yield {"event": "error", "data": json.dumps({"status": 500, "message": f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}, ensure_ascii=False)}
        return

    # 4. LLM ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ ë° ê²°ê³¼ ì²˜ë¦¬
    final_response_data = None
    full_ai_response = ""
    
    for event in get_llm_response(state['current_query'], state['messages'], state['context'], state['category']):
        event_data_str = event.get("data", "{}")
        event_data = json.loads(event_data_str)
        
        if event['event'] == 'challenge':
            full_ai_response += event_data.get("data", "")
        elif event['event'] == 'close':
            final_response_data = event_data.get("data")

        yield event

    # 5. ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ í›„ ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
    if final_response_data:
        eng_label = label_mapping.get(state['category'], "etc")
        if isinstance(final_response_data, dict) and "challenges" in final_response_data:
            for challenge in final_response_data["challenges"]:
                challenge["category"] = eng_label
        # ì‘ë‹µ ìµœìƒìœ„ì— í˜„ì¬ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ í•­ìƒ í¬í•¨ì‹œí‚´
        if isinstance(final_response_data, dict):
            final_response_data["category"] = state["category"]
        final_response_str = json.dumps(final_response_data, ensure_ascii=False)
        state['messages'].append({'role': 'assistant', 'content': final_response_str})
        state['response'] = final_response_str
    elif full_ai_response:
        state['messages'].append({'role': 'assistant', 'content': full_ai_response})
        state['response'] = full_ai_response
    
    logger.info(f"ğŸš€ğŸš€ğŸš€ ììœ  ëŒ€í™” ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ ğŸš€ğŸš€ğŸš€")

def clear_conversation(sessionId: str):
    """ëŒ€í™” ê¸°ë¡ ì‚­ì œ"""
    if sessionId in conversation_states:
        del conversation_states[sessionId]
        logger.info(f"ì„¸ì…˜ ID {sessionId}ì˜ ëŒ€í™” ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

def get_conversation_history(sessionId: str) -> List[Dict[str, str]]:
    """ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
    return conversation_states.get(sessionId, {}).get("messages", [])