# chatbot_router.py
from ..model.chatbot.LLM_chatbot_base_info_model import base_prompt, get_llm_response as get_base_info_llm_response, base_parser
from ..model.chatbot.LLM_chatbot_free_text_model import process_chat, clear_conversation, conversation_states, custom_prompt, get_llm_response as get_free_text_llm_response, retriever
from ..model.chatbot.chatbot_constants import label_mapping, ENV_KEYWORDS, BAD_WORDS, category_keywords
from fastapi import APIRouter, Query, HTTPException
from fastapi.responses import JSONResponse
from sse_starlette.sse import EventSourceResponse
from typing import Optional, Dict, Any, Generator
import json
import re
import logging
from fastapi.responses import StreamingResponse
from typing import Generator, AsyncGenerator
import asyncio
from urllib.parse import unquote  # URL ë””ì½”ë”©ì„ ìœ„í•œ import ì¶”ê°€

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

router = APIRouter()

# ë¹„-RAG ë°©ì‹ ì±Œë¦°ì§€ ì¶”ì²œ (SSE)
@router.get("/ai/chatbot/recommendation/base-info")
async def select_category(
    sessionId: Optional[str] = Query(None),
    location: Optional[str] = Query(None),
    workType: Optional[str] = Query(None),
    category: Optional[str] = Query(None)
):
    """
    ì‚¬ìš©ìì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¹œí™˜ê²½ ì±Œë¦°ì§€ë¥¼ ì¶”ì²œí•˜ëŠ” SSE ì—”ë“œí¬ì¸íŠ¸
    """
    # URL ë””ì½”ë”©
    if location:
        location = unquote(location)
    if workType:
        workType = unquote(workType)
    if category:
        category = unquote(category)
    
    # ì…ë ¥ê°’ ê²€ì¦
    if not location:
        print("location ëˆ„ë½")
        raise HTTPException(
            status_code=400,
            detail={
                "status": 400,
                "message": "locationì€ í•„ìˆ˜ì…ë‹ˆë‹¤.",
                "data": None
            }
        )
    if not workType:
        print("workType ëˆ„ë½")
        raise HTTPException(
            status_code=400,
            detail={
                "status": 400,
                "message": "workTypeì€ í•„ìˆ˜ì…ë‹ˆë‹¤.",
                "data": None
            }
        )
    if not category:
        print("category ëˆ„ë½")
        raise HTTPException(
            status_code=400,
            detail={
                "status": 400,
                "message": "categoryëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.",
                "data": None
            }
        )

    # ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬ ê²€ì¦
    if category not in label_mapping:
        print(f"ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬: {category}")
        print(f"ìœ íš¨í•œ ì¹´í…Œê³ ë¦¬ ëª©ë¡: {list(label_mapping.keys())}")
        raise HTTPException(
            status_code=400,
            detail={
                "status": 400,
                "message": "ìœ íš¨í•˜ì§€ ì•Šì€ ì„ íƒ í•­ëª©ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                "data": {
                    "invalidFields": ["category"]
                }
            }
        )

    # LLM í˜¸ì¶œì„ ìœ„í•œ prompt êµ¬ì„± (ë‹¨ìˆœí™”ëœ í”„ë¡¬í”„íŠ¸)
    prompt = base_prompt.format(
        location=location,
        workType=workType,
        category=category
    )

    # SSE ì‘ë‹µ ìƒì„±
    def event_generator():
        try:
            # ì„¸ì…˜ ì •ë³´ë§Œ ì €ì¥ (RAG ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
            if sessionId and sessionId not in conversation_states:
                conversation_states[sessionId] = {
                    "messages": [],
                    "category": category,
                    "base_category": category
                }

            # ì „ì²´ ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ëˆ„ì í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
            eng_label = label_mapping[category]

            for data_payload in get_base_info_llm_response(prompt, category):
                try:
                    event_type = data_payload.get("event")
                    data_from_llm_model = data_payload.get("data")

                    if not event_type or not data_from_llm_model:
                        continue  # ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë²¤íŠ¸ëŠ” ê±´ë„ˆë›°ê¸°

                    if event_type == "challenge":
                        yield {
                            "event": "challenge",
                            "data": data_from_llm_model
                        }

                    elif event_type == "close":
                        try:
                            parsed_json_data = json.loads(data_from_llm_model) if isinstance(data_from_llm_model, str) else data_from_llm_model

                            if not isinstance(parsed_json_data, dict):
                                raise ValueError("íŒŒì‹±ëœ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤.")

                            if "data" not in parsed_json_data or not isinstance(parsed_json_data["data"], dict):
                                raise ValueError("íŒŒì‹±ëœ ë°ì´í„°ì— ìœ íš¨í•œ 'data' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

                            final_data = parsed_json_data["data"]

                            if "challenges" not in final_data:
                                raise ValueError("íŒŒì‹±ëœ ë°ì´í„°ì— 'challenges' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

                            yield {
                                "event": "close",
                                "data": json.dumps({
                                    "status": 200,
                                    "message": "ëª¨ë“  ì±Œë¦°ì§€ ì¶”ì²œ ì™„ë£Œ",
                                    "data": final_data
                                }, ensure_ascii=False)
                            }
                            return
                            
                        except Exception as e:
                            yield {
                                "event": "error",
                                "data": json.dumps({
                                    "status": 500,
                                    "message": f"íŒŒì‹± ì‹¤íŒ¨: {str(e)}",
                                    "data": None
                                }, ensure_ascii=False)
                            }

                    elif event_type == "error":
                        yield {
                            "event": "error",
                            "data": data_from_llm_model
                        }

                except Exception as e:
                    logger.error(f"ì´ë²¤íŠ¸ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
                    yield {
                        "event": "error",
                        "data": json.dumps({
                            "status": 500,
                            "message": f"ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}",
                            "data": None
                        }, ensure_ascii=False)
                    }

        except Exception as e:
            logger.error(f"SSE ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}")
            yield {
                "event": "error",
                "data": json.dumps({
                    "status": 500,
                    "message": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ë¡œ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}",
                    "data": None
                }, ensure_ascii=False)
            }
        finally:
            # ì—°ê²° ì¢…ë£Œ ì´ë²¤íŠ¸ëŠ” ì´ë¯¸ íŒŒì‹±ëœ ë°ì´í„°ì™€ í•¨ê»˜ ì „ì†¡ë˜ì—ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì „ì†¡í•˜ì§€ ì•ŠìŒ
            pass

    return EventSourceResponse(
        event_generator(),
        media_type="text/event-stream",
        ping= None 
    )

# LangChain ê¸°ë°˜ RAG ì¶”ì²œ
@router.get("/ai/chatbot/recommendation/free-text")
async def freetext_rag(
    sessionId: Optional[str] = Query(None),
    message: Optional[str] = Query(None)
):
    """
    ììœ  ì±„íŒ… ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ì¹œí™˜ê²½ ì±Œë¦°ì§€ë¥¼ ì¶”ì²œí•˜ëŠ” SSE ì—”ë“œí¬ì¸íŠ¸ (ì§ì ‘ generate + streamer)
    """
    # URL ë””ì½”ë”© ì¶”ê°€
    if message:
        message = unquote(message)
    # ì…ë ¥ê°’ ê²€ì¦
    if not message or not message.strip():
        return EventSourceResponse(
            event_generator_error("messageëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.", 400),
            media_type="text/event-stream"
        )
    if len(message.strip()) < 5:
        return EventSourceResponse(
            event_generator_error("messageëŠ” ë¬¸ìì—´ì´ì–´ì•¼ í•˜ë©°, ìµœì†Œ 5ì ì´ìƒì˜ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.", 422),
            media_type="text/event-stream"
        )
    message_lower = message.lower()
    # ì¹´í…Œê³ ë¦¬ ê´€ë ¨ ìš”ì²­ ì²´í¬
    category_reset_keywords = ["ì›ë˜", "ì²˜ìŒ", "ì´ì „", "ì›ë˜ëŒ€ë¡œ", "ê¸°ì¡´", "ì¹´í…Œê³ ë¦¬"]
    is_category_request = any(keyword in message_lower for keyword in category_reset_keywords)
    # í™˜ê²½ ê´€ë ¨ ìš”ì²­ì´ ì•„ë‹ˆê³ , ì¹´í…Œê³ ë¦¬ ìš”ì²­ë„ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ê¸°ë³¸ ì‘ë‹µ (fallback ë¡œì§)
    is_env_related = any(k in message for k in ENV_KEYWORDS)
    contains_bad_words = any(b in message_lower for b in BAD_WORDS)
    async def event_generator():
        # ì„¸ì…˜ ì´ˆê¸°í™” (free-textëŠ” ëŒ€í™” ê¸°ë¡ì´ ì¤‘ìš”)
        if sessionId not in conversation_states:
            conversation_states[sessionId] = {
                "messages": [],
                "category": "ì œë¡œì›¨ì´ìŠ¤íŠ¸", # ê¸°ë³¸ê°’
                "base_category": "ì œë¡œì›¨ì´ìŠ¤íŠ¸"
            }
        # fallback ì¡°ê±´ ê²€ì‚¬ (í™˜ê²½ ê´€ë ¨ì´ ì•„ë‹ˆê±°ë‚˜ ë¹„ì†ì–´ê°€ í¬í•¨ëœ ê²½ìš°)
        if not is_category_request and (not is_env_related or contains_bad_words):
            logger.info(f"Fallback triggered: {message}")
            yield {
                "event": "error",
                "data": json.dumps({
                    "status": 200,
                    "message": "ì €ëŠ” ì¹œí™˜ê²½ ì±Œë¦°ì§€ë¥¼ ì¶”ì²œí•´ë“œë¦¬ëŠ” Leafresh ì±—ë´‡ì´ì—ìš”! í™˜ê²½ ê´€ë ¨ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì˜ ë„ì™€ë“œë¦´ ìˆ˜ ìˆì–´ìš”.",
                    "data": None
                }, ensure_ascii=False)
            }
            return # fallback ë©”ì‹œì§€ ì „ì†¡ í›„ ì¢…ë£Œ

        # ë¬¸ì¥ì—ì„œ ê°€ì¥ ë¨¼ì € ë“±ì¥í•œ í‚¤ì›Œë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒ (ì •ê·œí‘œí˜„ì‹ ê¸°ë°˜)
        import re  # ensure re is imported at top, but harmless to repeat
        min_pos = float('inf')
        selected_category = None
        for category, keywords in category_keywords.items():
            for keyword in keywords:
                match = re.search(re.escape(keyword), message)
                if match and match.start() < min_pos:
                    min_pos = match.start()
                    selected_category = category
        current_category = conversation_states[sessionId].get("category", "ì œë¡œì›¨ì´ìŠ¤íŠ¸")
        message_lower = message.lower()
        category_changed = False
        if selected_category:
            conversation_states[sessionId]["category"] = selected_category
            current_category = selected_category
            category_changed = True
        
        # 2. context ì¶”ì¶œ (RAG)
        # ğŸ“Œ í”„ë¡¬í”„íŠ¸ ìƒì„± ì „, ì‚¬ìš©ì ì •ë³´(location, workType)ë¥¼ í¬í•¨í•œ ë©”ì‹œì§€ ê¸°ë¡ êµ¬ì„±
        location = conversation_states[sessionId].get("location", "")
        workType = conversation_states[sessionId].get("workType", "")

        # ìµœê·¼ 3í„´(6ê°œ ë©”ì‹œì§€)ë§Œ ìœ ì§€
        recent_messages = conversation_states[sessionId]["messages"][-6:]  # ìµœê·¼ 3í„´ë§Œ ìœ ì§€í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ
        messages_history = f"ì‚¬ìš©ì ìœ„ì¹˜: {location}\nì‚¬ìš©ì ì§ì—…: {workType}\n"
        messages_history += "\n".join(
            [f"{msg['role']}: {msg['content']}" for msg in recent_messages]
        )

        # Set current context and category from retriever and conversation_states
        docs = retriever.get_relevant_documents(message)
        context = "\n".join([doc.page_content for doc in docs])
        current_category = conversation_states[sessionId]["category"]

        logger.info(f"RAG ê²€ìƒ‰ ì™„ë£Œ. ë¬¸ì„œ ìˆ˜: {len(docs)}")
        logger.info(f"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context)}")

        prompt = custom_prompt.format(
            context=context,  # RAG í™œì„±í™”
            query=message,
            messages=messages_history,
            category=current_category
        )

        # LLM ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
        try:
            full_response_text = ""
            for data_payload in process_chat(
                sessionId=sessionId,
                query=message,
                base_info_category=current_category
            ):
                event_type = data_payload.get("event")
                data_from_llm_model = data_payload.get("data")

                if not event_type or not data_from_llm_model:
                    continue  # ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë²¤íŠ¸ëŠ” ê±´ë„ˆë›°ê¸°

                # data_from_llm_modelì´ JSON ë¬¸ìì—´ì¸ ê²½ìš° ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹± (í‚¤ ì ‘ê·¼ ì „)
                parsed_data_payload = json.loads(data_from_llm_model) if isinstance(data_from_llm_model, str) else data_from_llm_model

                if event_type == "challenge":
                    # í† í° ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ full_response_textì— ëˆ„ì 
                    token_text = parsed_data_payload.get("data", "")
                    full_response_text += token_text

                    # í´ë¼ì´ì–¸íŠ¸ì— í† í° ì „ì†¡
                    yield {
                        "event": "challenge",
                        "data": json.dumps({
                            "status": 200,
                            "message": "í† í° ìƒì„±",
                            "data": token_text
                        }, ensure_ascii=False)
                    }

                elif event_type == "close":
                    # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸ (LLM ìµœì¢… ì‘ë‹µ ì „ì²´ë¥¼ ì €ì¥)
                    if sessionId in conversation_states:
                        conversation_states[sessionId]["messages"].append({
                            "role": "assistant",
                            "content": full_response_text
                        })

                    # ìµœì¢… ì¶”ì²œëœ ì±Œë¦°ì§€ ëª©ë¡ì— í˜„ì¬ ì¹´í…Œê³ ë¦¬ì˜ ì˜ë¬¸ ë¼ë²¨ì„ ì¶”ê°€
                    final_data = parsed_data_payload.get("data", None)
                    eng_label = label_mapping.get(current_category, "etc")
                    if final_data and "challenges" in final_data:
                        for challenge in final_data["challenges"]:
                            challenge["category"] = eng_label

                    yield {
                        "event": "close",
                        "data": json.dumps({
                            "status": 200,
                            "message": "ëª¨ë“  ì±Œë¦°ì§€ ì¶”ì²œ ì™„ë£Œ",
                            "data": final_data
                        }, ensure_ascii=False)
                    }
                    return

                elif event_type == "error":
                    yield {
                        "event": "error",
                        "data": data_from_llm_model
                    }

        except Exception as e:
            yield {
                "event": "error",
                "data": json.dumps({
                    "status": 500,
                    "message": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ë¡œ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}",
                    "data": None
                }, ensure_ascii=False)
            }
            return

    return EventSourceResponse(
        event_generator(),
        media_type="text/event-stream",
        ping= None 
    )

async def event_generator_error(message: str, status_code: int):
    """ì—ëŸ¬ ì´ë²¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ì œë„ˆë ˆì´í„°"""
    logger.error(f"SSE error event: {message} (status: {status_code})")
    yield {
        "event": "error",
        "data": json.dumps({
            "status": status_code,
            "message": message,
            "data": None
        }, ensure_ascii=False)
    }