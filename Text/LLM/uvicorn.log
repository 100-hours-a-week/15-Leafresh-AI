INFO:     Loading environment from '.env'
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:28<00:56, 28.13s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:56<00:28, 28.28s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:22<00:00, 27.15s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:22<00:00, 27.44s/it]
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-06-13 00:32:31,065 - WARNING - Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-06-13 00:32:31,066 - INFO - Hugging Face Hub에 성공적으로 로그인했습니다.
2025-06-13 00:32:31,066 - INFO - Current file: /home/ubuntu/15-Leafresh-AI/Text/LLM/model/chatbot/LLM_chatbot_base_info_model.py
2025-06-13 00:32:31,066 - INFO - Project root: /home/ubuntu/15-Leafresh-AI/Text/LLM
2025-06-13 00:32:31,066 - INFO - Model path: /home/ubuntu/mistral
2025-06-13 00:32:31,066 - INFO - 모델 경로: /home/ubuntu/mistral
2025-06-13 00:32:31,066 - INFO - 사용 가능한 디바이스: cuda
2025-06-13 00:32:31,066 - INFO - Loading tokenizer...
2025-06-13 00:32:32,635 - INFO - Loading model...
2025-06-13 00:32:33,387 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:05,  2.82s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:02,  2.42s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]
2025-06-13 00:32:40,628 - WARNING - Some parameters are on the meta device device because they were offloaded to the cpu.
2025-06-13 00:32:40,628 - INFO - Model loaded successfully!
2025-06-13 00:32:40,696 - INFO - Current file: /home/ubuntu/15-Leafresh-AI/Text/LLM/model/chatbot/LLM_chatbot_free_text_model.py
2025-06-13 00:32:40,696 - INFO - Project root: /home/ubuntu/15-Leafresh-AI/Text/LLM
2025-06-13 00:32:40,696 - INFO - Model path: /home/ubuntu/mistral
2025-06-13 00:32:40,696 - INFO - 모델 경로: /home/ubuntu/mistral
2025-06-13 00:32:40,696 - INFO - 사용 가능한 디바이스: cuda
2025-06-13 00:32:40,696 - INFO - Loading tokenizer...
2025-06-13 00:32:41,835 - INFO - Loading model...
2025-06-13 00:32:42,335 - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.81s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:03<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.64s/it]
2025-06-13 00:32:49,969 - WARNING - Some parameters are on the meta device device because they were offloaded to the cpu.
2025-06-13 00:32:49,969 - INFO - Model loaded successfully!
2025-06-13 00:32:50,076 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5
2025-06-13 00:32:53,134 - INFO - Use pytorch device_name: cuda
2025-06-13 00:32:54,307 - INFO - HTTP Request: GET https://f8879519-a1ba-47ef-b346-87fef37d0b57.us-east4-0.gcp.cloud.qdrant.io:6333/collections/ChatBot_context_collection "HTTP/1.1 200 OK"
INFO:     Started server process [1549]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
[Model Output] 새로 생성하려는 챌린지 이름은 '텀블러 챌린지'입니다.
기존 챌린지 이름 목록은 다음과 같습니다:
- 플로깅
- 비건 식단

기존 챌린지와 많은 부분 겹치는 경우에만 'No'라고 답해주세요. 
예를 들어 '텀블러 챌린지'와 '텀블러 이용 챌린지', '텀블러 사용 챌린지' 등은 모두 많은 부분이 겹치므로 'No'라고 답해주세요. 
챌린지의 이름이 환경과 관련이 없거나 의미가 모호한 경우 'No'라고 답해주세요. 
의미가 모호하거나 명확하지 않은 문장(예: 대충, 뭐든지, 그냥, 뭔가 등)이 포함되어 있으면 'No'라고 답해주세요. 
새로운 챌린지와 이름이 같거나, 단어는 다르지만 의미나 목적이 유사한 챌린지가 존재한다면 'No'라고 답해주세요.
단어 순서가 다르거나 '매일', '도전하기', '습관화하기' 등이 추가된 경우에도 동일한 챌린지로 판단합니다. 
스팸이나 광고성, 홍보성, 마케팅성 문구일 경우 'No'라고 답해주세요. 하지만, 친환경과 관련된 경우 'Yes'라고 답해주세요. 
특수문자만 들어간 경우, 숫자만 들어간 경우 'No'라고 답해주세요. 
같은 단어가 여러번 반복되는 경우 'No'라고 답해주세요. 
그렇지 않다면 'Yes'라고 답해주세요. 
답변은 반드시 'Yes.' 또는 'No.'로 시작해야 합니다. 

Yes.
[result]
 새로 생성하려는 챌린지 이름은 '텀블러 챌린지'입니다.
기존 챌린지 이름 목록은 다음과 같습니다:
- 플로깅
- 비건 식단

기존 챌린지와 많은 부분 겹치는 경우에만 'No'라고 답해주세요. 
예를 들어 '텀블러 챌린지'와 '텀블러 이용 챌린지', '텀블러 사용 챌린지' 등은 모두 많은 부분이 겹치므로 'No'라고 답해주세요. 
챌린지의 이름이 환경과 관련이 없거나 의미가 모호한 경우 'No'라고 답해주세요. 
의미가 모호하거나 명확하지 않은 문장(예: 대충, 뭐든지, 그냥, 뭔가 등)이 포함되어 있으면 'No'라고 답해주세요. 
새로운 챌린지와 이름이 같거나, 단어는 다르지만 의미나 목적이 유사한 챌린지가 존재한다면 'No'라고 답해주세요.
단어 순서가 다르거나 '매일', '도전하기', '습관화하기' 등이 추가된 경우에도 동일한 챌린지로 판단합니다. 
스팸이나 광고성, 홍보성, 마케팅성 문구일 경우 'No'라고 답해주세요. 하지만, 친환경과 관련된 경우 'Yes'라고 답해주세요. 
특수문자만 들어간 경우, 숫자만 들어간 경우 'No'라고 답해주세요. 
같은 단어가 여러번 반복되는 경우 'No'라고 답해주세요. 
그렇지 않다면 'Yes'라고 답해주세요. 
답변은 반드시 'Yes.' 또는 'No.'로 시작해야 합니다. 

Yes.
[answer] yes.
INFO:     127.0.0.1:40056 - "POST /ai/challenges/group/validation HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [1549]
